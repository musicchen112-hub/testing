
# ========== 1. é›²ç«¯ç’°å¢ƒè‡ªå‹•ä¿®å¾© ==========
def ensure_anystyle_installed():
    possible_paths = [
        "/home/appuser/.local/share/gem/ruby/3.1.0/bin",
        "/home/adminuser/.local/share/gem/ruby/3.1.0/bin",
        subprocess.getoutput("ruby -e 'print Gem.user_dir'") + "/bin"
    ]
    for p in possible_paths:
        if p not in os.environ["PATH"]:
            os.environ["PATH"] = p + os.pathsep + os.environ["PATH"]

    try:
        subprocess.run(["anystyle", "--version"], capture_output=True, check=True)
    except:
        with st.spinner("â˜ï¸ æ­£åœ¨åˆå§‹åŒ–é›²ç«¯ AnyStyle ç’°å¢ƒ..."):
            os.system("gem install anystyle-cli --user-install")
            new_path = subprocess.getoutput("ruby -e 'print Gem.user_dir'") + "/bin"
            if new_path not in os.environ["PATH"]:
                os.environ["PATH"] = new_path + os.pathsep + os.environ["PATH"]

ensure_anystyle_installed()

# app.py (ä¸€éµå ±è¡¨è‡ªå‹•åŒ–ç‰ˆ - æ¨™é¡Œè£œå¼·åœ°ç«¯ç‰ˆ)

import streamlit as st
import pandas as pd
import time
import os
import re
import ast 
from concurrent.futures import ThreadPoolExecutor, as_completed

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from modules.parsers import parse_references_with_anystyle
from modules.local_db import load_csv_data, search_local_database
from modules.api_clients import (
    get_scopus_key,
    get_serpapi_key,
    search_crossref_by_doi,
    search_crossref_by_text,
    search_scopus_by_title,
    search_scholar_by_title,
    search_scholar_by_ref_text,
    search_s2_by_title,
    search_openalex_by_title,
    check_url_availability
)

# ========== é é¢è¨­å®šèˆ‡æ¨£å¼ ==========
st.set_page_config(page_title="å¼•æ–‡æŸ¥æ ¸å ±è¡¨å·¥å…·", page_icon="ğŸ“Š", layout="wide")

st.markdown("""
<style>
    .main-header { font-size: 2.2rem; font-weight: bold; text-align: center; color: #4F46E5; margin-bottom: 5px; }
    .sub-header { text-align: center; color: #6B7280; margin-bottom: 2rem; }
    .status-badge { padding: 4px 10px; border-radius: 12px; font-size: 0.85em; font-weight: bold; }
    .ref-box { background-color: #F9FAFB; padding: 12px; border-radius: 8px; font-family: 'Courier New', monospace; font-size: 0.9em; border: 1px solid #E5E7EB; margin-top: 5px; }
    .report-card { background-color: #FFFFFF; padding: 20px; border-radius: 10px; border: 1px solid #E5E7EB; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
</style>
""", unsafe_allow_html=True)

# ========== Session State ==========
if "results" not in st.session_state: st.session_state.results = []

# ========== [æ ¸å¿ƒå·¥å…·å‡½æ•¸] ==========
def format_name_field(data):
    if not data: return None
    try:
        if isinstance(data, str):
            if not (data.startswith('[') or data.startswith('{')): return data
            try: data = ast.literal_eval(data)
            except: return data
        names_list = []
        data_list = data if isinstance(data, list) else [data]
        for item in data_list:
            if isinstance(item, dict):
                parts = [item.get('family', ''), item.get('given', '')]
                names_list.append(", ".join([p for p in parts if p]))
            else: names_list.append(str(item))
        return "; ".join(names_list)
    except: return str(data)

def refine_parsed_data(parsed_item):
    item = parsed_item.copy()
    raw_text = item.get('text', '').strip()

    # 1. åŸºç¤ç¬¦è™Ÿæ¸…æ´—
    for key in ['doi', 'url', 'title', 'date']:
        if item.get(key) and isinstance(item[key], str):
            item[key] = item[key].strip(' ,.;)]}>')

    title = item.get('title', '')

    # =========================================================
    # [NEW] Patch 1: ä¿®å¾© "ç¬¬äºŒä½œè€…æ®˜ç•™" å•é¡Œ
    # é‡å°: "& Heinzl, A.(2021). Real Title" é€™ç¨®è§£æéŒ¯èª¤
    # =========================================================
    if title and (title.startswith('&') or title.lower().startswith('and ')):
        # Regex é‚è¼¯ï¼š
        # ^&             -> ä»¥ & é–‹é ­
        # .+?            -> ä¸­é–“ä»»ä½•éå¹´ä»½çš„å­— (äººå)
        # \(?\d{4}\)?    -> æŠ“åˆ°å¹´ä»½ (ä¾‹å¦‚ 2021 æˆ– (2021))
        # [\.\s]+        -> å¹´ä»½å¾Œçš„å¥é»æˆ–ç©ºç™½
        # (.*)           -> æŠ“å–å‰©é¤˜çš„çœŸå¯¦æ¨™é¡Œ
        fix_match = re.search(r'^&(?:amp;)?\s*[^0-9]+?\(?\d{4}\)?[\.\s]+(.*)', title)
        if fix_match:
            cleaned_title = fix_match.group(1).strip()
            # ç¢ºä¿åˆ‡å®Œå‰©ä¸‹çš„é•·åº¦å¤ é•·ï¼Œæ‰æ›¿æ› (é¿å…åˆ‡å£)
            if len(cleaned_title) > 5:
                title = cleaned_title
                item['title'] = title

    # =========================================================
    # [NEW] Patch 2: å¼·åŠ›å»å™ª (é‡å° "2024. Title" æˆ– "Title. arXiv")
    # =========================================================
    if title:
        # å»æ‰é–‹é ­çš„ 4 ä½æ•¸å­—å¹´ä»½èˆ‡æ¨™é» (ä¾‹å¦‚ "2024. ")
        title = re.sub(r'^\s*\d{4}[\.\s]+', '', title)
        
        # å»æ‰çµå°¾çš„ arXiv, Available at... ç­‰å¸¸è¦‹é›œè¨Š
        title = re.sub(r'(?i)\.?\s*arXiv.*$', '', title)
        title = re.sub(r'(?i)\.?\s*Available.*$', '', title)
        
        item['title'] = title

    # 2. æ¨™é¡Œè£œæ•‘æ©Ÿåˆ¶ (é‡å°æ¨™é¡Œç‚ºç©º æˆ– æ¸…æ´—å¾Œè®Šå¾ˆçŸ­çš„æƒ…æ³)
    if not title or len(title) < 5:
        # [Pattern A] é‡å° "ç¸®å¯«: å®Œæ•´æ¨™é¡Œ" (å¦‚ StyleTTS 2)
        abbr_match = re.search(r'^([A-Z0-9\-\.\s]{2,12}:\s*.+?)(?=\s*[,\[]|\s*Available|\s*\(|\bhttps?://|\.|$)', raw_text)
        if abbr_match:
            item['title'] = abbr_match.group(1).strip()
        else:
            # [Pattern B] AnyStyle èª¤åˆ¤ç‚ºå‡ºç‰ˆå•†æˆ–æœŸåˆŠ
            for backup_key in ['publisher', 'container-title', 'journal']:
                val = item.get(backup_key)
                if val and len(str(val)) > 15:
                    item['title'] = str(val).strip()
                    break

        # [Pattern C] å¹´ä»½å®šä½æ³• (ä½¿ç”¨å¹´ä»½å»åŸæ–‡æ‰¾æ¨™é¡Œ)
        if (not item.get('title') or item['title'] == 'N/A') and item.get('date'):
            year_str = str(item['date'])[0:4] 
            if year_str.isdigit():
                # æŠ“å–å¹´ä»½å¾Œé¢çš„å…§å®¹
                fallback_match = re.search(rf'{year_str}\W+\s*(.+)', raw_text)
                if fallback_match:
                    candidate = fallback_match.group(1).strip()
                    # é€™è£¡ä¹Ÿè¦åšä¸€æ¬¡é›œè¨Šæ¸…æ´—ï¼Œç¢ºä¿è£œæ•‘å›ä¾†çš„æ¨™é¡Œä¹¾æ·¨
                    candidate = re.sub(r'(?i)\.?\s*arXiv.*$', '', candidate)
                    candidate = re.sub(r'(?i)\.?\s*Available.*$', '', candidate)
                    
                    if len(candidate) > 5:
                        item['title'] = candidate.strip(' .')

    # 3. DOI æå– (ä¿æŒä¸è®Š)
    url_val = item.get('url', '')
    if url_val:
        doi_match = re.search(r'(10\.\d{4,9}/[-._;()/:a-zA-Z0-9]+)', url_val)
        if doi_match:
            item['doi'] = doi_match.group(1).strip('.')

    # 4. ä½œè€…èˆ‡ç·¨è¼¯æ ¼å¼åŒ–
    if item.get('authors'): item['authors'] = format_name_field(item['authors'])
    if item.get('editor'): item['editor'] = format_name_field(item['editor'])
    
    return item

def check_single_task(idx, raw_ref, local_df, target_col, scopus_key, serpapi_key):
    ref = refine_parsed_data(raw_ref)
    title, text = ref.get('title', ''), ref.get('text', '')
    search_query = title if (title and len(title) > 8) else text[:120]
    doi, parsed_url = ref.get('doi'), ref.get('url')
    first_author = ref['authors'].split(';')[0].split(',')[0].strip() if ref.get('authors') else ""

    res = {"id": idx, "title": title, "text": text, "parsed": ref, "sources": {}, "found_at_step": None, "suggestion": None}

    # 1. Local DB
    if bool(re.search(r'[\u4e00-\u9fff]', search_query)) and local_df is not None and title:
        match_row, _ = search_local_database(local_df, target_col, title, threshold=0.85)
        if match_row is not None:
            res.update({"sources": {"Local DB": "åŒ¹é…æˆåŠŸ"}, "found_at_step": "0. Local Database"})
            return res

    # 2. Crossref
    if doi:
        _, url, _ = search_crossref_by_doi(doi, target_title=title if title else None)
        if url: 
            res.update({"sources": {"Crossref": url}, "found_at_step": "1. Crossref (DOI)"})
            return res
    
    url, _ = search_crossref_by_text(search_query, first_author)
    if url:
        res.update({"sources": {"Crossref": url}, "found_at_step": "1. Crossref (Search)"})
        return res

    # 3. Scopus & Others
    if scopus_key:
        # å‚³å…¥ first_author é€²è¡Œä½œè€…æ¯”å°
        url, _ = search_scopus_by_title(search_query, scopus_key, author=first_author)
        if url:
            res.update({"sources": {"Scopus": url}, "found_at_step": "2. Scopus"})
            return res

    # ä¿®æ”¹é€™è£¡çš„åˆ—è¡¨ï¼Œå°‡ Google Scholar çš„ lambda è£œä¸Š first_author
    for api_func, step_name in [(lambda: search_scholar_by_title(
    search_query, 
    serpapi_key, 
    author=first_author,     # å‚³å…¥ä½œè€… (æœƒè¢«ä¸Šé¢çš„é‚è¼¯è‡ªå‹•æ¸…æ´—)
    raw_text=raw_ref['text'] # å‚³å…¥å…¨æ–‡ (çµ¦ç¬¬ä¸‰é—œç”¨)
), "5. Google Scholar")]:
        try:
            url, _ = api_func()
            if url:
                res.update({"sources": {step_name.split(". ")[1]: url}, "found_at_step": step_name})
                return res
        except: pass

    # 4. Suggestion (Scholar Text Search)
    if serpapi_key:
        url_r, _ = search_scholar_by_ref_text(text, serpapi_key, target_title=title)
        if url_r: res["suggestion"] = url_r

    # 5. Website Check
    if parsed_url and parsed_url.startswith('http'):
        if check_url_availability(parsed_url):
            res.update({"sources": {"Direct Link": parsed_url}, "found_at_step": "6. Website / Direct URL"})
        else:
            res.update({"sources": {"Direct Link (Dead)": parsed_url}, "found_at_step": "6. Website (Link Failed)"})
    
    return res

# ========== å´é‚Šæ¬„è¨­å®š ==========
with st.sidebar:
    st.header("âš™ï¸ ç³»çµ±è¨­å®š")
    DEFAULT_CSV_PATH = "112ndltd.csv"
    local_df, target_col = None, None
    if os.path.exists(DEFAULT_CSV_PATH):
        local_df = load_csv_data(DEFAULT_CSV_PATH)
        if local_df is not None:
            st.success(f"âœ… å·²è¼‰å…¥æœ¬åœ°åº«: {len(local_df)} ç­†")
            target_col = "è«–æ–‡åç¨±" if "è«–æ–‡åç¨±" in local_df.columns else local_df.columns[0]
    
    scopus_key = get_scopus_key()
    serpapi_key = get_serpapi_key()
    st.divider()
    st.caption("API ç‹€æ…‹ç¢ºèª:")
    st.write(f"Scopus: {'âœ…' if scopus_key else 'âŒ'} | SerpAPI: {'âœ…' if serpapi_key else 'âŒ'}")

# ========== ä¸»é é¢æµç¨‹ ==========
st.markdown('<div class="main-header">ğŸ“š å­¸è¡“å¼•ç”¨è‡ªå‹•åŒ–æŸ¥æ ¸å ±è¡¨</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">æ•´åˆå¤šæ–¹è³‡æ–™åº« APIï¼Œä¸€éµç”¢å‡ºå¼•æ–‡é©—è­‰çµæœèˆ‡ä¸‹è¼‰ CSV</div>', unsafe_allow_html=True)

# 1. è¼¸å…¥å€
st.markdown("### ğŸ“¥ ç¬¬ä¸€æ­¥ï¼šè¼¸å…¥å¼•æ–‡å…§å®¹")
raw_input = st.text_area("è«‹ç›´æ¥è²¼ä¸Šåƒè€ƒæ–‡ç»åˆ—è¡¨ï¼š", height=250, placeholder="ä¾‹å¦‚ï¼š\nStyleTTS 2: Towards Human-Level Text-to-Speech...\nAIOS: LLM Agent Operating System...")

# 2. åŸ·è¡Œå€
if st.button("ğŸš€ é–‹å§‹å…¨è‡ªå‹•æ ¸å°ä¸¦ç”Ÿæˆå ±è¡¨", type="primary", use_container_width=True):
    if not raw_input:
        st.warning("âš ï¸ è«‹å…ˆè²¼ä¸Šæ–‡ç»å…§å®¹å†åŸ·è¡Œã€‚")
    else:
        st.session_state.results = []
        with st.status("ğŸ” æ­£åœ¨é€²è¡ŒæŸ¥æ ¸ä½œæ¥­...", expanded=True) as status:
            status.write("æ­£åœ¨è§£æå¼•ç”¨æ ¼å¼...")
            _, struct_list = parse_references_with_anystyle(raw_input)
            
            if struct_list:
                status.write(f"æ­£åœ¨é€£ç·šå„å¤§å­¸è¡“è³‡æ–™åº« (å…± {len(struct_list)} ç­†)...")
                progress_bar = st.progress(0)
                results_buffer = []
                with ThreadPoolExecutor(max_workers=5) as executor:
                    futures = {executor.submit(check_single_task, i+1, r, local_df, target_col, scopus_key, serpapi_key): i for i, r in enumerate(struct_list)}
                    for i, future in enumerate(as_completed(futures)):
                        results_buffer.append(future.result())
                        progress_bar.progress((i + 1) / len(struct_list))
                
                st.session_state.results = sorted(results_buffer, key=lambda x: x['id'])
                status.update(label="âœ… æ ¸å°ä½œæ¥­å®Œæˆï¼", state="complete", expanded=False)
            else:
                st.error("âŒ AnyStyle è§£æç•°å¸¸ï¼Œè«‹æª¢æŸ¥è¼¸å…¥å…§å®¹ã€‚")

# 3. å ±è¡¨é¡¯ç¤ºèˆ‡ä¸‹è¼‰å€
if st.session_state.results:
    st.divider()
    st.markdown("### ğŸ“Š ç¬¬äºŒæ­¥ï¼šæŸ¥æ ¸çµæœèˆ‡å ±è¡¨ä¸‹è¼‰")
    
    # çµ±è¨ˆå¡ç‰‡
    total_refs = len(st.session_state.results)
    verified_db = sum(1 for r in st.session_state.results if r.get('found_at_step') and "6." not in r.get('found_at_step'))
    failed_refs = total_refs - verified_db
    
    col1, col2, col3 = st.columns(3)
    col1.metric("ç¸½æŸ¥æ ¸ç­†æ•¸", total_refs)
    col2.metric("è³‡æ–™åº«åŒ¹é…æˆåŠŸ", verified_db)
    col3.metric("éœ€äººå·¥ç¢ºèª/ä¿®æ­£", failed_refs, delta_color="inverse")

    # ä¸‹è¼‰å ±è¡¨ï¼ˆç¶­æŒåŸæ¨£ï¼‰
    df_export = pd.DataFrame([{
        "ID": r['id'],
        "ç‹€æ…‹": r['found_at_step'] if r['found_at_step'] else "æœªæ‰¾åˆ°",
        "æŠ“å–æ¨™é¡Œ": r['title'],
        "åŸå§‹æ–‡ç»å…§å®¹": r['text'],
        "é©—è­‰ä¾†æºé€£çµ": next(iter(r['sources'].values()), "N/A") if r['sources'] else "N/A"
    } for r in st.session_state.results])

    csv_data = df_export.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="ğŸ“¥ ä¸‹è¼‰å®Œæ•´æŸ¥æ ¸å ±å‘Š (Excel å¯é–‹ CSV)",
        data=csv_data,
        file_name=f"Citation_Check_{time.strftime('%Y%m%d_%H%M')}.csv",
        mime="text/csv",
        use_container_width=True
    )

    # ========== 4. æŸ¥æ ¸æ¸…å–®æ˜ç´° (æ–°å¢éæ¿¾åŠŸèƒ½) ==========
    st.markdown("---")
    st.markdown("#### ğŸ” æŸ¥æ ¸æ¸…å–®æ˜ç´°")
    
    # åŒå­¸è¦æ±‚çš„äº”ç¨®éæ¿¾ç‹€æ…‹
    filter_option = st.radio(
        "é¡¯ç¤ºç¯©é¸é …ç›®ï¼š",
        ["å…¨éƒ¨é¡¯ç¤º", "âœ… è³‡æ–™åº«é©—è­‰", "ğŸŒ ç¶²ç«™æœ‰æ•ˆä¾†æº", "âš ï¸ ç¶²ç«™ (é€£ç·šå¤±æ•—)", "âŒ æœªæ‰¾åˆ°çµæœ"],
        horizontal=True
    )

    # åŸ·è¡Œéæ¿¾é‚è¼¯
    filtered_results = []
    for r in st.session_state.results:
        # ã€ä¿®æ­£é‡é»ã€‘ç¢ºä¿ step çµ•å°æ˜¯å­—ä¸²ï¼Œå³ä½¿åŸå§‹è³‡æ–™æ˜¯ None ä¹Ÿæœƒè®Šç‚ºç©ºå­—ä¸² ""
        raw_step = r.get('found_at_step')
        step = str(raw_step) if raw_step is not None else ""
        
        if filter_option == "å…¨éƒ¨é¡¯ç¤º":
            filtered_results.append(r)
        elif filter_option == "âœ… è³‡æ–™åº«é©—è­‰" and step and "6." not in step and "Failed" not in step:
            filtered_results.append(r)
        elif filter_option == "ğŸŒ ç¶²ç«™æœ‰æ•ˆä¾†æº" and "6." in step and "Failed" not in step:
            filtered_results.append(r)
        elif filter_option == "âš ï¸ ç¶²ç«™ (é€£ç·šå¤±æ•—)" and "Failed" in step:
            filtered_results.append(r)
        elif filter_option == "âŒ æœªæ‰¾åˆ°çµæœ" and (not step or step == ""):
            filtered_results.append(r)

    # é¡¯ç¤ºåˆ—è¡¨
    if not filtered_results:
        st.info(f"ç›®å‰æ²’æœ‰ç¬¦åˆã€Œ{filter_option}ã€çš„é …ç›®ã€‚")
    else:
        for item in filtered_results:
            raw_step = item.get('found_at_step')
            step = str(raw_step) if raw_step is not None else ""
            
            # æ ¹æ“šç‹€æ…‹æ±ºå®šåœ–ç¤º
            if not step:
                status_icon = "âŒ"
            elif "Failed" in step:
                status_icon = "âš ï¸"
            elif "6." in step:
                status_icon = "ğŸŒ"
            else:
                status_icon = "âœ…"

            with st.expander(f"{status_icon} ID {item['id']}ï¼š{item['text'][:80]}..."):
                st.markdown(f"**æŸ¥æ ¸çµæœï¼š** `{step if step else 'è³‡æ–™åº«æœªåŒ¹é…'}`")
                st.markdown(f"**åŸå§‹å…§å®¹ï¼š**")
                st.markdown(f"<div class='ref-box'>{item['text']}</div>", unsafe_allow_html=True)
                
                if item.get('sources'):
                    st.markdown("**ä¾†æºé€£çµï¼š**")
                    for src, link in item['sources'].items():
                        st.write(f"- {src}: {link}")
                
                # è‹¥æ²’æ‰¾åˆ°æˆ–å¤±æ•—ï¼Œé¡¯ç¤ºè£œæ•‘å»ºè­°
                if (not step or "Failed" in step) and item.get("suggestion"):
                    st.warning(f"ğŸ’¡ æ¨¡ç³Šæœå°‹å»ºè­°ï¼š[è«‹é»æ­¤æ‰‹å‹•ç¢ºèªç›¸ä¼¼æ–‡ç»]({item['suggestion']})")

else:
    st.info("ğŸ’¡ ç›®å‰å°šç„¡çµæœã€‚è«‹åœ¨ä¸Šæ–¹è¼¸å…¥æ¡†è²¼ä¸Šæ–‡ç»ï¼Œä¸¦é»æ“ŠæŒ‰éˆ•é–‹å§‹ã€‚")
